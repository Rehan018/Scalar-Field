# API Keys
SEC_API_KEY=your_sec_api_key_here
# GEMINI_API_KEY is no longer needed - using local Ollama models
# GEMINI_API_KEY=your_gemini_api_key_here

# Local LLM Configuration (Ollama)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Database Configuration
VECTOR_DB_PATH=./data/vector_db
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CONCURRENT_DOWNLOADS=5

# LLM Configuration (Legacy - now using Ollama)
LLM_MODEL=llama3.1:8b
MAX_TOKENS=2000
TEMPERATURE=0.1

# Embedding Configuration
EMBEDDINGS_DIR=./src/data/embeddings

# Search Configuration
MIN_SIMILARITY_THRESHOLD=0.05
TFIDF_SEMANTIC_WEIGHT=0.4
TFIDF_KEYWORD_WEIGHT=0.6